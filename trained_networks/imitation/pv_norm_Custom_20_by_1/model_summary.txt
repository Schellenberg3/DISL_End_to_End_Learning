Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 128, 128, 4) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 64, 64, 32)   1184        input_2[0][0]                    
__________________________________________________________________________________________________
activation (Activation)         (None, 64, 64, 32)   0           conv2d[0][0]                     
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 64, 64, 32)   128         activation[0][0]                 
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 48)   13872       batch_normalization[0][0]        
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 48)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 48)   192         activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 16, 16, 64)   27712       batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 16, 64)   0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 8, 8, 128)    73856       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 8, 8, 128)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 8, 8, 128)    512         activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 4, 4, 192)    221376      batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 4, 4, 192)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 4, 4, 192)    768         activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 2, 2, 256)    442624      batch_normalization_4[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 2, 2, 256)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 2, 2, 256)    1024        activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 1, 1, 256)    262400      batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 1, 1, 256)    0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 1, 1, 256)    1024        activation_6[0][0]               
__________________________________________________________________________________________________
flatten (Flatten)               (None, 256)          0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          65792       flatten[0][0]                    
__________________________________________________________________________________________________
input_1 (InputLayer)            [(None, 8)]          0                                            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 64)           576         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 256)          1024        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 64)           4160        dense[0][0]                      
__________________________________________________________________________________________________
dropout (Dropout)               (None, 256)          0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 256)          0           dropout[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 320)          0           dense_2[0][0]                    
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
reshape (Reshape)               (None, 1, 320)       0           concatenate[0][0]                
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1, 128)       41088       reshape[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1, 128)       16512       dense_4[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1, 8)         1032        dense_5[0][0]                    
==================================================================================================
Total params: 1,181,272
Trainable params: 1,178,808
Non-trainable params: 2,464
__________________________________________________________________________________________________


Training took a total time of 57.896998971002176 seconds.

Found an average accuracy of NO EVALUATION% with a max of -1 at episode-1 and a min of inf at episode-1.
 0 episodes were used for testing.